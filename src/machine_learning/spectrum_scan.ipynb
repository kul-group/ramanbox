{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing key packages\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.raman.sample_builder import SampleBuilder\n",
    "from src.raman.sample import Sample\n",
    "random.seed(42)\n",
    "from src.raman.constants import Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_train_val_test(sample_list, train_frac, val_frac):\n",
    "    train_num = int(len(sample_list)*train_frac)\n",
    "    val_num = int(len(sample_list)*val_frac)\n",
    "    test_num = len(sample_list) - train_num - val_num\n",
    "    assert train_num != 0 or train_frac == 0, 'train fraction too small'\n",
    "    assert val_num !=0 or val_frac == 0, 'val fraction too small'\n",
    "    index_list = random.shuffle([i for i in range(0, len(sample_list))])\n",
    "    train_vals = sample_list[index_list[0:train_num]]\n",
    "    val_vals = sample_list[index_list[train_num: val_num]]\n",
    "    test_vals = sample_list[index_list[val_num:-1]]\n",
    "\n",
    "    return train_vals, val_vals, test_vals\n",
    "\n",
    "def make_df(sample_list):\n",
    "    df = pd.DataFrame()\n",
    "    for sample in sample_list:\n",
    "       df.append(sample.to_pandas(), ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_X_Y(df, remove_maybe_uncat=True):\n",
    "    if remove_maybe_uncat:\n",
    "        df = df[(df['labels'] == Label.GOOD ) & (df['labels'] == Label.BAD)]\n",
    "\n",
    "    X = df['spectrum'].to_numpy()\n",
    "    Y_obj = df['labels'].to_numpy\n",
    "    Y = np.array([y.value for y in Y_obj])\n",
    "    return X, Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% define helper function\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set Directory of Labeled raman data and split into test, train val\n",
    "labeled_data_dir = '/data/'\n",
    "net_cdf_files = glob.glob(os.path.join(labeled_data_dir, '*.nc'))\n",
    "sample_list = []\n",
    "for file in net_cdf_files:\n",
    "    sample_list.append(Sample.build_from_netcdf(file))\n",
    "\n",
    "train_samples, val_samples, test_samples = split_train_val_test(sample_list, 0.6, 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make a training test and val dataframe\n",
    "train_df = make_df(train_samples)\n",
    "val_df = make_df(val_samples)\n",
    "test_df = make_df(test_samples)\n",
    "\n",
    "X_train, y_train = get_X_Y(train_df)\n",
    "X_val, y_val = get_X_Y(val_df)\n",
    "X_test, y_test = get_X_Y(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Build Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "import xgboost as xgb\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create classifiers\n",
    "lr = LogisticRegression()\n",
    "gnb = GaussianNB()\n",
    "svc = LinearSVC(C=1.0)\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Plot calibration plots\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "for clf, name in [(lr, 'Logistic'),\n",
    "                  (gnb, 'Naive Bayes'),\n",
    "                  (svc, 'Support Vector Classification'),\n",
    "                  (rfc, 'Random Forest')]:\n",
    "    clf.fit(X_train, y_train)\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        prob_pos = clf.predict_proba(X_test)[:, 1]\n",
    "    else:  # use decision function\n",
    "        prob_pos = clf.decision_function(X_test)\n",
    "        prob_pos = \\\n",
    "            (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "\n",
    "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "             label=\"%s\" % (name, ))\n",
    "\n",
    "    ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
    "             histtype=\"step\", lw=2)\n",
    "\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "ax2.set_xlabel(\"Mean predicted value\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}